---
title: "cgd_exploration_geospatial_R"
output:
  html_document:
    df_print: paged
---

```{r}

# install.packages("sf")
# install.packages("leaflet")
library(sf)
library(tidyverse)
library(leaflet)

```

# Analyzing Aggravated Burglaries in Davidson County
### Part 1: Data Preparation

I have been provided these three datasets for this project:

1. burglaries_2023.csv: Contains data on the aggravated burglary incidents in Davidson County. This was obtained from https://data.nashville.gov/Police/Metro-Nashville-Police-Department-Incidents/2u6v-ujjs.
```{r}
# read the csv of burglaries data into the notebook

burglary_incidents <- read_csv('../data/burglaries_2023.csv')

# view the dataset

burglary_incidents

```

Investigate the ethnicity column some: 

```{r}

# investigate the ethnicity column some

unique(burglary_incidents[["victim_ethnicity"]])

```


2. census.csv: Census tract level data on population and median income. This was obtained from the US Census American Community Survey.

```{r}

# read the csv of census data into the notebook

census <- read_csv('../data/census.csv')

# view the dataset

census

```
```{r}

sort(unique(census[["tract"]]))

```
```{r}
sort(unique(dav_cty_census_tracts[["TRACTCE"]]))

```


3. DC: A shapefile containing Davidson County census tracts

```{r}

# read in the shape file data for Davidson county census tracts
# read in the DC file data

dav_cty_census_tracts <- read_sf('../data/DC/DC.shp')
dav_cty_census_tracts

# burglary_incidents
```
```{r}
dav_cty_census_tracts |> 
  ggplot() +
  geom_sf()
```
```{r}
dav_cty_census_tracts |> 
  ggplot() +
  geom_sf(aes(fill = ALAND))
```



Perform a spatial join to determine the census tract in which each burglary occurred. Hint: You may want to make use of the st_as_sf function in order to convert the burglaries data into an sf object.

```{r}

# performed spatial join 

burglary_incidents

burglary_incidents_mapped <- st_as_sf(
  burglary_incidents |> 
    drop_na(latitude) |> 
    drop_na(longitude),
    coords = c('longitude', 'latitude'),
    crs = st_crs(dav_cty_census_tracts)
)

burglary_incidents_mapped


```

Rename column in Davidson county census tract data so that the merge goes more smoothly.

```{r}

dav_cty_census_tracts <- rename(dav_cty_census_tracts, tract_name = NAME)

```


Merge census csv data with dav_cty_census_tracts DC shape file data.


```{r}

census_tracts <- merge(dav_cty_census_tracts, census, by.x = "TRACTCE", by.y = "tract", all = TRUE)

census_tracts
# burglary_incidents_mapped

```

```{r}

census_tracts |> 
  ggplot() +
  geom_sf()

```

```{r}

# burglary_incidents_mapped_filtered <- st_filter(burglary_incidents_mapped, census_tracts)

```


```{r}


census_tracts |> 
   ggplot() +
   geom_sf() +
   geom_sf(data = burglary_incidents_mapped, size = 0.1)




```


After performing the spatial join, merge in the census data. Note: Make sure that the final dataset contains all census tracts, even those with zero burglaries.

```{r}

burglary_census_combo <- st_join(burglary_incidents_mapped, census_tracts, join = st_within, left=FALSE)


```

```{r}

census_tracts |> 
   ggplot() +
   geom_sf() +
   geom_sf(data = burglary_census_combo, size = 0.1)

```

```{r}

burglary_census_combo

```


### Part 2: Exploratory Analysis

Perform some exploratory analysis on your prepared dataset.

Classes of the two datasets:

```{r}

class(census_tracts)
class(burglary_census_combo)

```

Curious as to the highest number of victims in one burglary.

```{r}

burglary_census_combo |>
  filter(victim_number == max(victim_number, na.rm = TRUE))

```
Limit dataset to non repeated incident numbers and locate the highest number of victims per indcident number. 

```{r}

real_num_burglaries <- burglary_census_combo |>
  group_by(incident_number) |>
  filter(victim_number == max(victim_number, na.rm = TRUE)) |>
  arrange(desc(victim_number))

real_num_burglaries

```
Calculate the accurate number of burglaries in each tract.


```{r}

burglaries_per_tract_real <- real_num_burglaries |> 
  st_drop_geometry() |> 
  group_by(TRACTCE) |> 
  count(name = "num_burglaries") |> 
  arrange(desc(num_burglaries))

burglaries_per_tract_real

```
Comparing the non filtered number to the result before filtering:


```{r}

burglaries_per_tract <- burglary_census_combo |> 
  st_drop_geometry() |> 
  group_by(TRACTCE) |> 
  count(name = "num_burglaries") |> 
  arrange(desc(num_burglaries))

burglaries_per_tract

```

Aggregate the data by census tract. Warning: each incident can appear multiple times if there are multiple victims, so be sure that you aren't double-counting any incidents.


```{r}

burglaries_per_tract_real

```

Which census tract had the highest number of burglaries? 

```{r}

burglaries_per_tract_real[1,]

```


```{r}

burglary_census_combo_latlong <- burglary_census_combo %>%
    mutate(long = unlist(map(burglary_census_combo$geometry,1)),
           lat = unlist(map(burglary_census_combo$geometry,2)))

burglary_census_combo_latlong

```


```{r}

# real_num_burglaries
# burglary_census_combo
# burglary_incidents_mapped_filtered

leaflet(data = burglary_census_combo_latlong |> 
          drop_na(lat) |>
         filter(`TRACTCE` == "016000")
        ) |> 
  addTiles() |>
  addMarkers(~long,
             ~lat,
             popup = ~as.character(`victim_number`),
             label = ~as.character(`victim_number`)
             )
```



```{r}

tract_num = "016000"
# library(magrittr)
# df %<>%
#    mutate(size = factor(size))

# burglary_census_combo_latlong <- burglary_census_combo_latlong |>
#   mutate(incident_number = factor(incident_number))

census_tracts |> 
   filter(TRACTCE == tract_num) |> 
   ggplot() +
   geom_sf() +
   geom_sf(data =  burglary_census_combo_latlong |>
             filter(TRACTCE == tract_num),
           aes(color = as.character(`incident_number`)))


```

Which census tract had the highest number of burglaries per 1000 residents?


```{r}
# dividing the number of victims in the specified population 
# by the total number of persons in the population and 
# multiplying the rate by 1,000.

highest_burgs_per_pop <- real_num_burglaries |>
  mutate(high_burg_per_pop = 1000*(victim_number/population)) |>
  arrange(desc(high_burg_per_pop))


highest_burgs_per_pop$TRACTCE[1]

```


We're interested in the relationship between median income and number of aggravated burglaries, so examine those variables on their own and together to see what you can find. You may want to perform additional calculations, create plots, etc.

```{r}


burglary_census_combo_latlong$income_level <- with(burglary_census_combo_latlong, factor(
                            findInterval(median_income, c(-Inf,
                               quantile(median_income, probs=c(0.25, .5, .75)), Inf)), 
                            labels=c("lowest","low","medium", "high")
      ))


unique(burglary_census_combo_latlong[["income_level"]])

burglary_census_combo_latlong

```

```{r}

burgs_num_per_tract_real <- merge(census, burglaries_per_tract_real, by.x="tract", by.y="TRACTCE", all.x=TRUE) #- pop and median income data - 
burgs_num_per_tract_real
```

```{r}
burgs_num_per_tract_real_pos <- burgs_num_per_tract_real |>
  filter(median_income >= 0)

burgs_num_per_tract_real_pos
```

# Part 3: Statistical Modeling

Fit a Poisson regression model with target variable the rate of burglaries per census tract and with predictor the median income. Offset using the log of the population so that we are looking at the rate of burglaries per population instead of the number of burglaries. How can you interpret the meaning of the output? How do the estimates from the model compare to the observed data?

```{r}

# burg_median_income_lr <- glm(incident_number ~ median_income, data = burglary_census_combo_latlong)
# summary(burg_median_income_lr)



```



```{r}

burg_median_income_lr <- glm(
  num_burglaries ~ median_income,
  data = burgs_num_per_tract_real_pos,
  family = 'poisson',
  offset=log(population)
)
summary(burg_median_income_lr)

```

Interpret the coefficient you get for median_income
Hint: You can use the coef function to extract the coefficients from a model.

```{r}

burg_median_income_lr |> coef() |> exp()

```

```{r}
 
# Baby’s birthweight = Intercept(based on mother’s race) + β
#  * mother’s age
# 
# 
# Essentially you’re saying that your data is broken down into 3 racial groups, and you want to model your data as having the same slope governing how birthweight changes with mother’s age, but potentially different intercepts. Here’s a picture of what’s happening.
# 
# # Calculate race-specific intercepts
# intercepts <- c(coef(birthwt.lm)["(Intercept)"],
#                 coef(birthwt.lm)["(Intercept)"] + coef(birthwt.lm)["raceother"],
#                 coef(birthwt.lm)["(Intercept)"] + coef(birthwt.lm)["racewhite"])
# 
# lines.df <- data.frame(intercepts = intercepts,
#                        slopes = rep(coef(birthwt.lm)["mother.age"], 3),
#                        race = levels(birthwt$race))
# 
# qplot(x = mother.age, y = birthwt.grams, color = race, data = birthwt) + 
#   geom_abline(aes(intercept = intercepts, 
#                   slope = slopes, 
#                   color = race), data = lines.df)

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


